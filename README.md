



æœŸæœ« Lab 3 ç´€éŒ„

å¯¦ä½œçš„éƒ¨åˆ†å˜—è©¦å¾ˆå¤šæ–¹æ³•ï¼Œ

1. [SSVEP](#SSVEP )
2. [FFT](#FFT)
3. [alpha æ³¢](#alpha)
4. [blink eye (æœ€å¾Œä½¿ç”¨é€™å€‹)](#blink_eye)

# SSVEP 

ä½¿ç”¨è¢å¹•é–ƒçˆä¸åŒé »ç‡ä¾†åˆ¤æ–· classï¼Œç›¯è‘—ä¸åŒå¹³ç‡ä¾†åˆ¤æ–·ä¸åŒè…¦æ³¢ã€‚å»ºè­°ä¸è¦ä½¿ç”¨é€™å€‹ï¼Œåœ¨è’é›†è³‡æ–™æœƒè’é›†åˆ°çœ¼ç›çæ‰

## è’é›†è³‡æ–™

å› ç‚ºæº–ç¢ºåº¦å¾ˆ real-time ä¸Šé¢å¯¦æ¸¬å•é¡Œï¼Œå’Œè¢å¹•é–ƒçˆé »ç‡å•é¡Œï¼Œé€™éƒ¨åˆ†è’é›†äº†å¾ˆå¤šä¸åŒçš„è³‡æ–™ã€‚

1. è¢å¹•åŒæ™‚é–ƒçˆ 3 å€‹é »ç‡ 
2. è¢å¹•é–ƒçˆåˆ†åˆ¥ 3 å€‹é »ç‡ (å’Œè’é›†å®Œå¾ˆå¤šè³‡æ–™å¾Œæ‰ç™¼ç¾è¢å¹•é–ƒçˆé »ç‡ä¸ä¸€æ¨£...)

### é »ç‡å›ºå®š

è¦–çª—éƒ½æ˜¯ä½¿ç”¨ `psychopy` å¯¦ä½œ

> 1

é »ç‡çš„éƒ¨åˆ†ä¸€é–‹å§‹ä½¿ç”¨ sin æ³¢å‘ˆç¾ï¼Œè®“é€æ˜åº¦æœƒéš¨ä¸åŒé »ç‡çš„ sin æ³¢è®ŠåŒ–

```python
clock = core.Clock()
while clock.getTime() < duration:
    t = clock.getTime()
    for i, stim in enumerate(stimuli):
        freq = frequencies[i]
        # sinæ³¢æ±ºå®šé–ƒçˆ
        stim.opacity = 1.0 if np.sin(2 * np.pi * freq * t) > 0 else 0.0
        stim.draw()
    win.flip()
```

ä½†æ˜¯é€™å€‹é »ç‡ä¸¦ä¸æœƒå›ºå®šï¼Œæ¯æ¬¡åŸ·è¡Œé »ç‡å¥½åƒæœ‰æ‰€ä¸åŒ (æ ¹æ“šå—è©¦è€…åé¥‹

> 2

å¾Œä¾†ä½¿ç”¨ä¸‹åˆ—æ–¹æ³•ï¼Œè®“é »ç‡æ˜¯æ¯æ¬¡åŸ·è¡Œå›ºå®šçš„ï¼Œé€éæŠ“å–

ä½†æ˜¯åœ¨åƒè€ƒç¶²é  https://omids.github.io/quickssvep/ï¼Œç™¼ç¾é »ç‡è·Ÿä¸Šé¢çš„ä¸¦ä¸ä¸€è‡´

```python
frame_rate = win.getActualFrameRate(nIdentical=60, nMaxFrames=120, nWarmUpFrames=60)
n_frames = int(duration * frame_rate)
frames_per_cycle = frame_rate / target_freq
pattern = np.array([(i % frames_per_cycle) < (frames_per_cycle / 2) for i in range(n_frames)])
for i in range(n_frames):
	stimuli[target_idx].opacity = 1.0 if pattern[i] else 0.0
	stimuli[target_idx].draw()
	win.flip()
```



> 3

æœ€å¾Œï¼Œç™¼ç¾é‚„æ˜¯ä½¿ç”¨ 1 çš„æ–¹æ³•ï¼Œä½†æ˜¯æ™‚é–“åœ¨æœ€é–‹å§‹å®£å‘Šï¼Œä¸¦æ”¹æˆå–ç§’æ•¸æ˜¯åœ¨å“ªè£¡ç‚ºåŸºæº–ï¼Œé »ç‡æ‰é”åˆ°ç©©å®š

```python
clock = core.Clock()
while clock.getTime() < duration:
	t = stim_clock.getTime() # æ™‚é–“å¦å¤–è¨ˆç®—ï¼Œåœ¨ä¸€é–‹å§‹å°± declare
	phase = (t * frequencies[target_idx]) % 1  # å– 0~1
	stimuli[target_idx].opacity = 1.0 if phase < 0.5 else 0.0
	stimuli[target_idx].draw()
	win.flip()	
```





### è’é›†å¯¦éš›å±•ç¤º

`get_ssvep_data_simple.py`

è¨“ç·´æµç¨‹éƒ½ä¸€æ¨£ï¼Œæ¯å€‹ trailï¼Œä¸­é–“å‡ºç¾åå­—(1s) -> cue(1s) -> å‡ºç¾é »ç‡åœ–ç‰‡ (5s) -> rest (2s)

ä½¿ç”¨ä¸‹åœ–ä¸‰å€‹é »ç‡ä¸€å¼µåœ–ç‰‡

![image-20250607075034501](picture/image-20250607075034501.png)

`get_sssvep_data_new.py`

ä½¿ç”¨åƒæ˜¯ä¸‹åœ–å–®å€‹é »ç‡å’Œåœ–ç‰‡

![image-20250607075151331](picture/image-20250607075151331.png)



### è³‡æ–™ç´€éŒ„

æ¯å€‹äººè’é›†çš„ trail æ•¸é‡ï¼Œæ¯å€‹ trail ç´„ç‚º 6 ç§’ (æœ‰æ™‚å€™è’é›† trail æœƒæ²’æœ‰éŒ„åˆ° å£¬å¨ ç‚ºæœ€å¤§å—å®³è€… XD

|        | simple (æœ€é–‹å§‹ï¼Œä¸‰å€‹é »ç‡) |   new (å–®å€‹é »ç‡)    |
| :----: | :-----------------------: | :-----------------: |
| é­ä»²å½¥ |           `37`            |   `37*4+60*2=268`   |
| å¼µæ™‰ç¿ |        `37*3=101`         |    `60*2+37=157`    |
| æ—æ˜±é™ |         `37*2=74`         |        `37`         |
| è³´å£¬å¨ |             0             | `90*2+15+16+60=271` |
| é™³æŸç¿” |             0             |          0          |

æ—æ˜±é™ e ç‚º reasting state

## è¨“ç·´æ–¹æ³•

é€™è£¡æ ¹æ“šè¨“ç·´ `get_sssvep_data_new.py` çš„æ–¹æ³•é€²è¡Œè¨è«–

ä½¿ç”¨ `SCCNet`ã€`EEGNet` å’Œ [`ESNet`](https://github.com/YuDongPan/SSVEPNet/blob/master/Model/SSVEPNet.py) æ¸¬è©¦ï¼Œæº–ç¢ºåº¦ EEGNet > ESNet> SCCNet ï¼Œæ¨¡å‹è¤‡é›œåº¦ ESNet > SCCNet  > EEGNet 



### preprocess

ç‚ºäº†æ¨¡æ“¬å¯¦éš›æ‡‰ç”¨æƒ…æ³ï¼Œæ‰€ä»¥é¸æ“‡å…ˆåˆ‡å† band passï¼Œæœ¬ä¾†æœ‰ down sample to 250 Hzï¼Œä½†æ˜¯å¾Œä¾†ç™¼ç¾ä¸ down sample åè€Œæ•ˆæœæ›´å¥½ï¼Œå¯èƒ½æ˜¯å› ç‚ºå«æœ‰æ›´å¤šæ•¸æ“šå¯åˆ†æ

å…ˆåˆ‡ segments > padding > Bandpass filter (1 to 40 Hz) > åˆ‡æ‰å¤šé¤˜ padding çš„ size > å›å‚³è™•ç†å¾Œçš„ segment

```python
# padding å¾Œ Bandpass
s_padded = np.concatenate([
    s_ds[:buffer_ds][::-1],  # å‰ bufferï¼Œåè½‰é¡åƒ
    s_ds,
    s_ds[-buffer_ds:][::-1]  # å¾Œ bufferï¼Œåè½‰é¡åƒ
], axis=0)
s_f = filtfilt(b, a, s_padded, axis=0) # Bandpass filter
s_final = s_f[buffer_ds: -buffer_ds] # è£æ‰ buffer éƒ¨åˆ†
```



#### train_parameter

`epochs=500, batch_size=16, learning rate=0.0001`



æœ€å¾Œæº–ç¢ºç‡æ¯å€‹äººä¸åŒï¼Œæ¯æ¬¡è’é›†è³‡æ–™ç„¶å¾Œæ¸¬è©¦æº–ç¢ºç‡æœ‰æ™‚å€™ç‚º 0.5ï¼Œæœ‰æ™‚å€™ç‚º 0.7 ï¼Œä½†æ˜¯æœ‰æ™‚å€™æº–ç¢ºç‡å¯ä»¥ä¾†åˆ° 9 æˆã€‚ä½†æ˜¯æº–ç¢ºç‡å†é«˜ï¼Œæœ€å¾Œå¯¦æ¸¬çš„æ™‚å€™æ„Ÿè¦ºéƒ½åƒæ˜¯ä¸€å¨ ğŸ’©ã€‚



## online_test

é€™è£¡æ ¹æ“šæ¸¬è©¦ `get_sssvep_data_new.py` çš„æ–¹æ³•é€²è¡Œè¨è«–

ä¸»ç¨‹åº (`ssvep_window`) é¡¯ç¤ºå°æ‡‰çš„é »ç‡ï¼Œä¸¦ä½¿ç”¨ wd åˆ‡æ›é »ç‡ï¼Œç„¶å¾Œçœ‹çœ‹å°æ‡‰è…¦æ³¢æœ‰æ²’æœ‰é¡¯ç¤ºå°æ‡‰çš„ class

æˆ‘å€‘å‰µå»ºäº†ä¸‰å€‹ thread ç¬¬ä¸€å€‹ (`read_eeg`) ç”¨ä¾†è®€å– eeg dataï¼Œç¬¬äºŒå€‹ (`predict_loop`) ç”¨ä¾† predictionï¼Œæœ€å¾Œä¸€å€‹ (`report_history`) ç”¨ä¾†è¿”å›æœ€å¾Œçµæœï¼Œå‰å…©å€‹ thread æœ‰å…±ç”¨ global value bufferã€‚

### read_eeg

åœ¨è®€å– eeg data çš„ thread è£¡é¢

æˆ‘å€‘æŠŠ 5 ç§’çš„è³‡æ–™å­˜å…¥åˆ° buffer è£¡é¢ï¼Œç„¶å¾Œ real time è®€å– cygenus å‚³çš„è³‡æ–™ï¼Œç•¶æ•¸æ“šæ»¿äº”ç§’ (5*sample rate)ï¼Œæˆ‘å€‘å°±è®“ä¸€ç­†è³‡æ–™é€²ä¾†ï¼Œä¸€ç­†è³‡æ–™å°±å‡ºå»ã€‚sample å– 4 å€‹ channel data (fp1, pf2, o1, o2)

```python
sample, _ = inlet.pull_sample()
sample = np.array(sample[0:2] + sample[4:6]).reshape(-1, 1)  # shape: (4,1)
eeg_buffer[:, :-1] = eeg_buffer[:, 1:]  # å‘å·¦ç§»å‹•ä¸€æ ¼ï¼Œä¸Ÿæ‰æœ€èˆŠçš„
eeg_buffer[:, -1] = sample.flatten()
```



### predict_loop

åœ¨ predicitonï¼Œæœƒä½¿ç”¨ä¹‹å‰è¨“ç·´ç”¢å‡ºçš„æ¨¡å‹ `train_n.pth`ï¼Œload æ¨¡å‹å¾Œé¤µå°æ‡‰è³‡æ–™é€²å»ã€‚è³‡æ–™é¤µé€²å»ä¹‹å‰æœƒåšå‰è™•è£¡

```python
outputs = model(x_batch)
prediction = int(torch.argmax(outputs).cpu().item())
history.append(prediction)
```



#### preprocess

é€™è£¡åšçš„å’Œè¨“ç·´çš„æ™‚å€™åšçš„å¾ˆåƒ padding > Bandpass filter (1 to 40 Hz)

ç•¶è³‡æ–™éƒ½è™•è£¡å®Œæˆå¾Œä¸¦å¾—åˆ°é æ¸¬çµæœï¼Œç„¶å¾ŒæœƒæŠŠçµæœæ”¾å…¥åˆ° history è£¡é¢ã€‚

### report_history

ä½¿ç”¨ history ç´€éŒ„ä¹‹å‰å¹¾å€‹ predictionï¼Œè®“è¼¸å‡ºçµæœæœƒæ˜¯ histroy è£¡é¢æœ€å¤šçš„çµæœã€‚æ¯ 3 ç§’è¼¸å‡ºä¸€æ¬¡æœ€çµ‚çµæœ



# FFT

å˜—è©¦ä½¿ç”¨ FFT ç„¶å¾Œæ ¹æ“šè¨“ç·´è³‡æ–™ç”¢å‡ºçš„çµæœé »ç‡ä¾†å€åˆ†ç›®å‰å—è©¦è€…æƒ³çš„æ˜¯å“ªå€‹é »ç‡

ä½¿ç”¨ FFT å‡ºä¾†çš„ 3 å€‹ threshold ä¾†åˆ¤æ–·ï¼Œä½†æ˜¯åœ¨ print å‡ºä¾† threshold å’Œ è³‡æ–™çš„æ•¸æ“šå¾Œï¼Œç™¼ç¾è®ŠåŒ–å¾ˆå¤§ï¼Œå¾ˆé›£å€åˆ†é¡åˆ¥ï¼Œæ‰€ä»¥å¾Œä¾†å°±æ”¹å˜—è©¦å…¶ä»–æ–¹æ³•



# alpha

å› ç‚ºåœ¨ [Mind-controlled-car](https://github.com/CECNL/BCI_lab1-Mind-controlled-car) è£¡é¢ä½¿ç”¨ alpha å¯ä»¥åšç°¡å–®çš„äºŒåˆ†é¡ï¼Œç„¶å¾Œé‚£æ™‚å€™ SSVEP æ•ˆæœåˆä¸æ˜¯å¾ˆå¥½ï¼Œæ‰€ä»¥æˆ‘å€‘æ”¹ä½¿ç”¨çœ‹çœ‹ alphaï¼Œç„¶å¾ŒæŠŠ alpha æ”¹æˆç”¨ç¥ç¶“ç¶²è·¯è¨“ç·´ç„¶å¾Œæ¸¬è©¦

## è’é›†è³‡æ–™

ä½¿ç”¨ sounddevice æ’­æ”¾è²éŸ³ï¼Œè®“å—è©¦è€…è½åˆ°è²éŸ³å¾Œå¼µçœ¼é–‰çœ¼ï¼Œç„¶å¾Œç´€éŒ„ start, end å’Œ label åˆ°æ–‡ä»¶è£¡é¢

```python
t = np.linspace(0, duration, int(sr * duration), False)
tone = np.sin(freq * t * 2 * np.pi)
sounddevice.play(tone, sr)
```

### è³‡æ–™ç´€éŒ„

åªæœ‰ æ˜±é™ æœ‰è’é›†è³‡æ–™ï¼Œç¸½å…±è’é›† `40*2` å€‹ trailï¼Œæ¯å€‹ trail ä¸€å…± 10 ç§’ (ä¸€å€‹ session å¼µçœ¼é–‰çœ¼ 20 æ¬¡)



æœ€å¾Œåœ¨æ¸¬è©¦çš„æ™‚å€™ï¼Œç™¼ç¾æ•ˆæœå…¶å¯¦å’Œä½¿ç”¨ threshold çš„å·®ä¸å¤šï¼Œéƒ½æœ‰é»é›£æ§åˆ¶ã€‚å› ç‚ºæ‰€å‰©æ™‚é–“ä¸å¤šï¼Œæ‰€ä»¥ç„¶å¾Œ æ˜±é™ ç™¼ç¾åœ¨ blink eye çš„æ™‚å€™ fp1 fp2 çš„æ³¢å½¢è‚‰çœ¼å¯è¦‹çš„è®ŠåŒ–ï¼Œå’Œå–®çœ¼æ‰çš„æ™‚å€™å¯ä»¥æ§åˆ¶ fp1 æˆ–æ˜¯ fp2ï¼Œæ‰€ä»¥æœ€å¾Œæ”¹ä½¿ç”¨ blink eye ä¾†åˆ¤æ–·ï¼Œä¸ä½¿ç”¨ MLï¼Œè€Œæ˜¯ä½¿ç”¨ raw eeg signal ç›´æ¥åˆ¤æ–·



# blink_eye

æˆ‘å€‘æœ€å¾Œæ¡ç”¨çš„æ–¹æ³•ï¼Œé€™å€‹æ–¹æ³•çš„æ­£ç¢ºç‡é«˜çš„åš‡äººï¼Œå°¤å…¶é…ä¸Šæœ€å¼·å¤§è…¦ æ˜±é™ å¾Œ

### æ³¢å½¢ç‰¹æ€§

åœ¨æ²’æœ‰ blink eye çš„æ™‚å€™æ³¢å½¢å¾ˆç©©å®š

![image-20250607092337697](picture/image-20250607092337697.png)

ç•¶æˆ‘å€‘é›™çœ¼ä¸€ç›´ blink çš„æ™‚å€™æ³¢å½¢æœƒå¦‚ä¸‹ï¼Œå¯ä»¥çœ‹åˆ°æ³¢å½¢çš„å¼·åº¦æ˜é¡¯è®Šå¤§

![image-20250607092814575](picture/image-20250607092814575.png)

ç•¶å–®çœ¼ blink çš„æ™‚å€™ï¼Œæœƒæœ‰ç‰¹å®šçš„ channel æ³¢å½¢å¹…åº¦è®ŠåŒ–ï¼Œä½†æ˜¯é€™å€‹çœ‹äººï¼Œå¦‚æœä¸èƒ½åª blink ä¸€çœ¼ï¼Œé‚£å°±æœƒå¦å¤–ä¸€å€‹ channel ä¹Ÿæœƒè·Ÿè€…è®ŠåŒ–ï¼Œå–®çœ¼ blink çš„å¼·åº¦æ¯”é›™çœ¼ä¾†çš„å¤§å¾ˆå¤š

![image-20250607092555819](picture/image-20250607092555819.png)

![image-20250607092452109](picture/image-20250607092452109.png)

é€éä»¥ä¸Šç‰¹æ€§ï¼Œæˆ‘å€‘è¨­è¨ˆä¸€å€‹æ ¹æ“šæ³¢å½¢å¼·åº¦ä¾†åˆ¤æ–·ä½¿ç”¨è€…ç›®å‰æƒ³è¦ç™¼é€æŒ‡ä»¤çš„ç³»çµ±

## method

é€éè¨ˆç®— fp1 fp2 åœ¨ä¸€å®šæ™‚é–“å…§çš„å¼·åº¦ï¼Œæˆ‘å€‘ä½¿ç”¨æœ€å¤§å€¼å’Œæœ€å°å€¼è¨ˆç®—

```python
amplitude_fp1 = np.max(eeg_buffer[0]) - np.min(eeg_buffer[0])
amplitude_fp2 = np.max(eeg_buffer[1]) - np.min(eeg_buffer[1])
```

ç„¶å¾ŒæŠŠå€¼å­˜å…¥ queue è£¡é¢ï¼Œè®“æœ€å¾Œçµæœè¼¸å…¥ä¸è¦å¤ªä¸ç©©å®š

```python
fp1_amplitude_queue.append(amplitude_fp1)
fp2_amplitude_queue.append(amplitude_fp2)
```



æˆ‘å€‘ blink åˆ¤æ–·æ˜¯æ ¹æ“š `CHECK_INTERVAL` è®Šæ•¸ï¼Œæœ€å¾Œæ¸¬ 0.2 åˆ¤æ–·ä¸€æ¬¡å‰›å‰›å¥½



ç•¶å¼·åº¦è¶…å‡ºæˆ‘å€‘çš„ thresholdï¼Œé‚£å°±ä»£è¡¨ä½¿ç”¨è€…è¦åŸ·è¡Œå°æ‡‰çš„æŒ‡ä»¤ï¼Œæˆ‘å€‘åªæœ‰ä¸‰åˆ†é¡ï¼Œå› ç‚ºæˆ‘å€‘çš„æœ€å¼·å¤§è…¦èªªä»–å·¦çœ¼ blink çš„æ™‚å€™å³çœ¼ä¹Ÿæœƒ blinkã€‚

```python
if fp1_moderate > half and fp2_moderate > half:
	blink_class = 3  # ä¸­ç­‰å¼·åº¦åŒæ­¥ blink
	ser.write(b'4')  # è¨­å®š turn right
elif fp2_strong > half and fp1_strong <= half:
	blink_class = 2  # å„ªå…ˆï¼šå³å´å¼· blink
elif fp1_strong > half and fp2_strong <= half:
	blink_class = 1  # å„ªå…ˆï¼šå·¦å´å¼· blink
	ser.write(b'1')  # è¨­å®š car forward
else:
	blink_class = 0  # ç„¡ blink
	ser.write(b'0')  # è¨­å®š car stay
```





é€™å€‹æ–¹æ³•å¾ˆçœ‹è…¦æ³¢ï¼Œå› ç‚ºåœ¨ä¸€é–‹å§‹çš„æ™‚å€™è…¦æ³¢æ³¢å½¢ä¸€å®šè¦ç©©ï¼Œç„¶å¾Œ blink ä¸€å®šè¦æœ‰å€åˆ†ï¼Œæ‰èƒ½ä½¿ç”¨é€™å€‹æ–¹æ³•ã€‚
